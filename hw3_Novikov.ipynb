{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dhaA1R7xUcDQ"
   },
   "source": [
    "# Домашнее задание 3. \n",
    "\n",
    "## Предсказание пользовательской оценки отеля по тексту отзыва."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QjksJgxNUcDr"
   },
   "source": [
    "Мы собрали для вас отзывы по 1500 отелям из совершенно разных уголков мира. Что это за отели - секрет. Вам дан текст отзыва и пользовательская оценка отеля. Ваша задача - научиться предсказывать оценку отеля по отзыву. Данные можно скачать [тут](https://www.kaggle.com/c/hseds-texts-2020/data?select=train.csv)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HtrS2NqaUcDv"
   },
   "source": [
    "Главная метрика - Mean Absolute Error (MAE). Во всех частях домашней работы вам нужно получить значение MAE не превышающее 1. В противном случае мы будем вынуждены не засчитать задание :( "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_BaPh8e9UcDx"
   },
   "source": [
    "Для измерения качества вашей модели используйте разбиение данных на train и test и замеряйте качество на тестовой части."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-d1ji5loUcD2"
   },
   "source": [
    "#### Про данные:\n",
    "Каждое ревью состоит из двух текстов: positive и negative - плюсы и минусы отеля. В столбце score находится оценка пользователя - вещественное число 0 до 10. Вам нужно извлечь признаки из этих текстов и предсказать по ним оценку."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m8lx_cXNUcD4"
   },
   "source": [
    "Удачи! 💪"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mz9EOjMLUcD8"
   },
   "source": [
    "#### Использовать внешние данные для обучения строго запрещено. Можно использовать предобученные модели из torchvision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Arb3-pPuUfdp",
    "outputId": "124258e4-69ef-451e-eb6c-4ce1b99a3836"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-12-22 06:44:24--  https://www.dropbox.com/s/vjenzws8velxh32/test.csv\n",
      "Resolving www.dropbox.com (www.dropbox.com)... 162.125.1.18, 2620:100:6016:18::a27d:112\n",
      "Connecting to www.dropbox.com (www.dropbox.com)|162.125.1.18|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: /s/raw/vjenzws8velxh32/test.csv [following]\n",
      "--2020-12-22 06:44:24--  https://www.dropbox.com/s/raw/vjenzws8velxh32/test.csv\n",
      "Reusing existing connection to www.dropbox.com:443.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://ucf7ac7469a447c1117bc97e9d4a.dl.dropboxusercontent.com/cd/0/inline/BFh9wVWMjy9bn9ITw99YLdDUMHwbB6jZ2zrmajMlAi8jzSLPndAK0J3xDO4a6vOWBL3m1YJvXZdF9anUgbiHi2Ag-5l2rUNLq3cVJEZN4jS0hXORVXlwhoWyG0Zb__7fJ9k/file# [following]\n",
      "--2020-12-22 06:44:24--  https://ucf7ac7469a447c1117bc97e9d4a.dl.dropboxusercontent.com/cd/0/inline/BFh9wVWMjy9bn9ITw99YLdDUMHwbB6jZ2zrmajMlAi8jzSLPndAK0J3xDO4a6vOWBL3m1YJvXZdF9anUgbiHi2Ag-5l2rUNLq3cVJEZN4jS0hXORVXlwhoWyG0Zb__7fJ9k/file\n",
      "Resolving ucf7ac7469a447c1117bc97e9d4a.dl.dropboxusercontent.com (ucf7ac7469a447c1117bc97e9d4a.dl.dropboxusercontent.com)... 162.125.1.15, 2620:100:6016:15::a27d:10f\n",
      "Connecting to ucf7ac7469a447c1117bc97e9d4a.dl.dropboxusercontent.com (ucf7ac7469a447c1117bc97e9d4a.dl.dropboxusercontent.com)|162.125.1.15|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 4497121 (4.3M) [text/plain]\n",
      "Saving to: ‘test.csv’\n",
      "\n",
      "test.csv            100%[===================>]   4.29M  27.4MB/s    in 0.2s    \n",
      "\n",
      "2020-12-22 06:44:24 (27.4 MB/s) - ‘test.csv’ saved [4497121/4497121]\n",
      "\n",
      "--2020-12-22 06:44:25--  https://www.dropbox.com/s/9xwbmexkmv6d7y4/train.csv\n",
      "Resolving www.dropbox.com (www.dropbox.com)... 162.125.1.18, 2620:100:6016:18::a27d:112\n",
      "Connecting to www.dropbox.com (www.dropbox.com)|162.125.1.18|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: /s/raw/9xwbmexkmv6d7y4/train.csv [following]\n",
      "--2020-12-22 06:44:25--  https://www.dropbox.com/s/raw/9xwbmexkmv6d7y4/train.csv\n",
      "Reusing existing connection to www.dropbox.com:443.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://uc6c57912cada4fa02a69e48afc0.dl.dropboxusercontent.com/cd/0/inline/BFhyPYInfDfEZSRo0N5VXS_TDJbSfBG046lBnWeMuCNXplmT5jZktix6glssEZ2EdIm7gBZmKK2o3r1OoGtjhVAnMSkqGCePKSMFJ6ZS2kz0kI4Uka0wzsiz8n_B_wBeIk4/file# [following]\n",
      "--2020-12-22 06:44:25--  https://uc6c57912cada4fa02a69e48afc0.dl.dropboxusercontent.com/cd/0/inline/BFhyPYInfDfEZSRo0N5VXS_TDJbSfBG046lBnWeMuCNXplmT5jZktix6glssEZ2EdIm7gBZmKK2o3r1OoGtjhVAnMSkqGCePKSMFJ6ZS2kz0kI4Uka0wzsiz8n_B_wBeIk4/file\n",
      "Resolving uc6c57912cada4fa02a69e48afc0.dl.dropboxusercontent.com (uc6c57912cada4fa02a69e48afc0.dl.dropboxusercontent.com)... 162.125.1.15, 2620:100:6016:15::a27d:10f\n",
      "Connecting to uc6c57912cada4fa02a69e48afc0.dl.dropboxusercontent.com (uc6c57912cada4fa02a69e48afc0.dl.dropboxusercontent.com)|162.125.1.15|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 22811739 (22M) [text/plain]\n",
      "Saving to: ‘train.csv’\n",
      "\n",
      "train.csv           100%[===================>]  21.75M  91.2MB/s    in 0.2s    \n",
      "\n",
      "2020-12-22 06:44:26 (91.2 MB/s) - ‘train.csv’ saved [22811739/22811739]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://www.dropbox.com/s/vjenzws8velxh32/test.csv\n",
    "!wget https://www.dropbox.com/s/9xwbmexkmv6d7y4/train.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "id": "M5bjqgBfUcD-",
    "outputId": "7782ea60-1284-435e-a99a-edbed2a88838"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>negative</th>\n",
       "      <th>positive</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00003c6036f30f590c0ac435efb8739b</td>\n",
       "      <td>There were issues with the wifi connection</td>\n",
       "      <td>No Positive</td>\n",
       "      <td>7.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00004d18f186bf2489590dc415876f73</td>\n",
       "      <td>TV not working</td>\n",
       "      <td>No Positive</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000cf900cbb8667fad33a717e9b1cf4</td>\n",
       "      <td>More pillows</td>\n",
       "      <td>Beautiful room Great location Lovely staff</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0000df16edf19e7ad9dd8c5cd6f6925e</td>\n",
       "      <td>Very business</td>\n",
       "      <td>Location</td>\n",
       "      <td>5.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00025e1aa3ac32edb496db49e76bbd00</td>\n",
       "      <td>Rooms could do with a bit of a refurbishment ...</td>\n",
       "      <td>Nice breakfast handy for Victoria train stati...</td>\n",
       "      <td>6.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          review_id  ... score\n",
       "0  00003c6036f30f590c0ac435efb8739b  ...   7.1\n",
       "1  00004d18f186bf2489590dc415876f73  ...   7.5\n",
       "2  0000cf900cbb8667fad33a717e9b1cf4  ...  10.0\n",
       "3  0000df16edf19e7ad9dd8c5cd6f6925e  ...   5.4\n",
       "4  00025e1aa3ac32edb496db49e76bbd00  ...   6.7\n",
       "\n",
       "[5 rows x 4 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('/content/train.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M2VbRsHPUcEA"
   },
   "source": [
    "Предобработка текста может сказываться на качестве вашей модели.\n",
    "Сделаем небольшой препроцессинг текстов: удалим знаки препинания, приведем все слова к нижнему регистру. \n",
    "Однако можно не ограничиваться этим набором преобразований. Подумайте, что еще можно сделать с текстами, чтобы помочь будущим моделям? Добавьте преобразования, которые могли бы помочь по вашему мнению."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "spK9tjkmUcEB"
   },
   "source": [
    "Также мы добавили разбиение текстов на токены. Теперь каждая строка-ревью стала массивом токенов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i1y6NciiUcEI",
    "outputId": "f251e80c-1779-4d0c-b9df-cbf459068124"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "noise = ['the', 'a', 'an', 'at', 'and', 'for', 'of', 'or', 'on', 'in', 'to', 'this', 'that', 'be', 'there', 'is', 'was', 'are', 'were',\n",
    "         'i', 'me', 'we', 'as', 'it', 'by', 'so', 'from', 'my', 'with']\n",
    "exclude = set(string.punctuation)\n",
    "#exclude.update(noise)\n",
    "stop_words = stopwords.words('english')\n",
    "#stop_words.remove('no')\n",
    "#stop_words.remove('not')\n",
    "#stop_words.append('negative')\n",
    "exclude.update(stop_words)\n",
    "\n",
    "def process_text(text):\n",
    "    return ' '.join([word for word in word_tokenize(text.lower()) if word not in exclude])\n",
    "\n",
    "def process_text2tokens(text):\n",
    "    return [word for word in word_tokenize(text.lower()) if word not in exclude]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "11urK-zyUcEJ"
   },
   "outputs": [],
   "source": [
    "#df['negative'] = df['negative'].apply(process_text)\n",
    "#df['positive'] = df['positive'].apply(process_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "pbOpfgYz_Qm2"
   },
   "outputs": [],
   "source": [
    "df['review'] = df['negative'] + ' ' + df['positive']\n",
    "#df['review'] = str(df['review'])\n",
    "df['tokens'] = df['review'].apply(process_text2tokens)\n",
    "df['review'] = df['review'].apply(process_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "1XmO4RpyUcEK"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_train, df_test = train_test_split(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 249
    },
    "id": "-cvet03DO56S",
    "outputId": "4f3fb046-06a5-47af-e2b4-b06b843a6ada"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>negative</th>\n",
       "      <th>positive</th>\n",
       "      <th>score</th>\n",
       "      <th>review</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>90356</th>\n",
       "      <td>e72b6c270b897b5eab79e6a34ee9f93c</td>\n",
       "      <td>No Negative</td>\n",
       "      <td>ALWAYS GOOD</td>\n",
       "      <td>10.0</td>\n",
       "      <td>negative always good</td>\n",
       "      <td>[negative, always, good]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53534</th>\n",
       "      <td>88ff7bdd6ac37329d17a3d02c67b9de3</td>\n",
       "      <td>The hotel is close to the tube That means it ...</td>\n",
       "      <td>The location is fabulous if you are looking f...</td>\n",
       "      <td>9.2</td>\n",
       "      <td>hotel close tube means super convenient totall...</td>\n",
       "      <td>[hotel, close, tube, means, super, convenient,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89707</th>\n",
       "      <td>e57511e30ae172d719253017a4b23163</td>\n",
       "      <td>No Negative</td>\n",
       "      <td>Excellent location friendly helpful staff</td>\n",
       "      <td>10.0</td>\n",
       "      <td>negative excellent location friendly helpful s...</td>\n",
       "      <td>[negative, excellent, location, friendly, help...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40800</th>\n",
       "      <td>68ae7309f46ac65ee90656198c95d84e</td>\n",
       "      <td>When we checked in the first room was smelly ...</td>\n",
       "      <td>Italian restaurant food was good</td>\n",
       "      <td>4.6</td>\n",
       "      <td>checked first room smelly took hour hotel allo...</td>\n",
       "      <td>[checked, first, room, smelly, took, hour, hot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28767</th>\n",
       "      <td>4a11cb3136fbfc9c41f9c7c689821e6d</td>\n",
       "      <td>Four steps up to the lift</td>\n",
       "      <td>Great location and very clean</td>\n",
       "      <td>9.6</td>\n",
       "      <td>four steps lift great location clean</td>\n",
       "      <td>[four, steps, lift, great, location, clean]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              review_id  ...                                             tokens\n",
       "90356  e72b6c270b897b5eab79e6a34ee9f93c  ...                           [negative, always, good]\n",
       "53534  88ff7bdd6ac37329d17a3d02c67b9de3  ...  [hotel, close, tube, means, super, convenient,...\n",
       "89707  e57511e30ae172d719253017a4b23163  ...  [negative, excellent, location, friendly, help...\n",
       "40800  68ae7309f46ac65ee90656198c95d84e  ...  [checked, first, room, smelly, took, hour, hot...\n",
       "28767  4a11cb3136fbfc9c41f9c7c689821e6d  ...        [four, steps, lift, great, location, clean]\n",
       "\n",
       "[5 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cl0_RSuBUcEL"
   },
   "source": [
    "### Часть 1. 1 балл"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JG90yT9oUcEM"
   },
   "source": [
    "Обучите логистическую регрессию на TF-IDF векторах текстов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "bi02J8HYUcEN"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "XjIRVXUCuAr9"
   },
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(min_df=50, max_features=50000).fit(list(df_train['review']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "wBHAybboJ84f"
   },
   "outputs": [],
   "source": [
    "train_x = tfidf.transform(list(df_train['review']))\n",
    "train_y = df_train['score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "xCdnSUalLUqn"
   },
   "outputs": [],
   "source": [
    "test_x = tfidf.transform(list(df_test['review']))\n",
    "test_y = df_test['score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "BjejNpSxp3kp"
   },
   "outputs": [],
   "source": [
    "lm = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mHbqWU7Op38g",
    "outputId": "8ccd94f0-1254-4e56-c78d-2a778c163285"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tLhjVNJEN3HT",
    "outputId": "dd7ce409-bd39-49ab-ebad-48100615d249"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x2365 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 12 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "oo3WttTwLfpm"
   },
   "outputs": [],
   "source": [
    "y_pred = lm.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "32SjRYEEu2zt"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error as MAE_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ERxOZ3qxLfgp",
    "outputId": "f7413813-9a49-4432-c047-a5abdbfe70cc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9045907127434957"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAE_score(test_y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nlvLo7LwAzm-"
   },
   "source": [
    "ура уже не 0 за дз"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aVmEE6QPUcEO"
   },
   "source": [
    "### Часть 2. 3 балла"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xrd-Shj5UcEP"
   },
   "source": [
    "Обучите логистическую регрессию на усредненных Word2Vec векторах. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "BY8fElC-UcEP"
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "XKAgKCoI2sUU"
   },
   "outputs": [],
   "source": [
    "model = Word2Vec(list(df_train['tokens']), size=1000, min_count = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KyWAfkQNVELJ",
    "outputId": "7a919cf8-be91-44ac-c1bb-2254e972934a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n"
     ]
    }
   ],
   "source": [
    "def mean_vector(word2vec_model, string):\n",
    "    # remove out-of-vocabulary words\n",
    "    string = [word for word in string if word in word2vec_model.vocab]\n",
    "    if string:\n",
    "      return np.mean(word2vec_model[string], axis=0)\n",
    "    else:\n",
    "      return np.zeros(1000)\n",
    "\n",
    "trainx=[]\n",
    "i = 0\n",
    "for string in df_train['tokens']:\n",
    "    trainx.append(mean_vector(model.wv, string))\n",
    "    if i % 10000 == 0:\n",
    "      print(i)\n",
    "    i+=1\n",
    "\n",
    "train_X = np.array(trainx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XB3PkkBcka25",
    "outputId": "6b60befb-1176-4217-cd93-908d0d43cbaf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10000\n",
      "20000\n"
     ]
    }
   ],
   "source": [
    "testx=[]\n",
    "i = 0\n",
    "for string in df_test['tokens']:\n",
    "    testx.append(mean_vector(model.wv, string))\n",
    "    if i % 10000 == 0:\n",
    "      print(i)\n",
    "    i+=1\n",
    "\n",
    "test_X = np.array(testx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9-mSr9h8kaxI",
    "outputId": "7135b02e-b51e-4f2f-a2d3-6a51321b3bb7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.966234700883463"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.fit(train_X, train_y)\n",
    "y_pred = lm.predict(testx)\n",
    "MAE_score(test_y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LveY9HAAi1iK"
   },
   "source": [
    "Штош получилось похуже чем на TF-IDF, но что поделать"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0TfzPE_hUcEP"
   },
   "source": [
    "Усредняя w2v вектора, мы предполагаем, что каждое слово имеет равноценный вклад в смысл предложения, однако это может быть не совсем так. Теперь попробуйте воспользоваться другой концепцией и перевзвесить слова при получении итогового эмбеддинга текста. В качестве весов используйте IDF (Inverse document frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "8tUlghhiwIDh"
   },
   "outputs": [],
   "source": [
    "idf_dict = dict(zip(tfidf.get_feature_names(), tfidf.idf_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "a34T0DlPUcEQ"
   },
   "outputs": [],
   "source": [
    "def calc_idf(texts):\n",
    "    texts = [ idf_dict[word] - 1 for word in texts]\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aZEESlq31Say",
    "outputId": "7267fa65-006e-4c0f-b30c-8036178fd290"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n"
     ]
    }
   ],
   "source": [
    "trainx=[]\n",
    "i = 0\n",
    "\n",
    "for string in df_train['tokens']:\n",
    "    string = [word for word in string  if word in model.wv.vocab and str(word) in idf_dict]\n",
    "    if string:\n",
    "        idfs = calc_idf(string)\n",
    "        w2vs = model.wv[string]\n",
    "        strx = []\n",
    "        for ii in range(len(string)):\n",
    "            strx.append(w2vs[ii] * idfs[ii])\n",
    "                          \n",
    "        trainx.append(np.mean(strx, axis=0))\n",
    "    else:\n",
    "        trainx.append(np.zeros(1000))\n",
    "    \n",
    "    if i % 10000 == 0:\n",
    "      print(i)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7JVQRy8RAe8T",
    "outputId": "98d9407d-d1e5-4f8c-fc4d-9c0798bf5c9b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10000\n",
      "20000\n"
     ]
    }
   ],
   "source": [
    "testx=[]\n",
    "i = 0\n",
    "\n",
    "for string in df_test['tokens']:\n",
    "    string = [word for word in string  if word in model.wv.vocab and str(word) in idf_dict]\n",
    "    if string:\n",
    "        idfs = calc_idf(string)\n",
    "        w2vs = model.wv[string]\n",
    "        strx = []\n",
    "        for ii in range(len(string)):\n",
    "            strx.append(w2vs[ii] * idfs[ii])\n",
    "                          \n",
    "        testx.append(np.mean(strx, axis=0))\n",
    "    else:\n",
    "        testx.append(np.zeros(1000))\n",
    "    \n",
    "    if i % 10000 == 0:\n",
    "      print(i)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "6h9yMHKRKiSV"
   },
   "outputs": [],
   "source": [
    "train_X = np.array(trainx)\n",
    "test_X = np.array(testx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qy5FGcHtAetn",
    "outputId": "cdafbd0a-dfea-488a-d4a0-9da269b647d5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9659285655975172"
      ]
     },
     "execution_count": 28,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.fit(train_X, train_y)\n",
    "y_pred = lm.predict(test_X)\n",
    "MAE_score(test_y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UKRBKmxABKR9"
   },
   "source": [
    "В принципе качество не сильно улучшилось, но скорее всего проблема в том что я все равно усреднял (из условия не вполне понятно надо ли это было делать) + не подбирал размер эмбеддинга"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3FBsgxBjUcER"
   },
   "source": [
    "Проведите эксперименты с размерностью эмбеддинга. Для каждого из двух методов постройте график зависимости качества модели от размерности эмбеддинга. \n",
    "#### Сделайте выводы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "iLn_CckjNXnz"
   },
   "outputs": [],
   "source": [
    "def mean_vector(word2vec_model, string, e):\n",
    "    string = [word for word in string if word in word2vec_model.vocab]\n",
    "    if string:\n",
    "      return np.mean(word2vec_model[string], axis=0)\n",
    "    else:\n",
    "      return np.zeros(e)\n",
    "\n",
    "\n",
    "def textembedding1(w2vmodel, text, e):\n",
    "    res = []\n",
    "    i = 0\n",
    "    for string in text:\n",
    "        res.append(mean_vector(w2vmodel.wv, string, e))\n",
    "    \n",
    "        #if i % 10000 == 0:\n",
    "        #    print(i)\n",
    "        #i+=1\n",
    "\n",
    "    return np.array(res)\n",
    "\n",
    "def textembedding2(w2vmodel, text, e):\n",
    "    res = []\n",
    "    i = 0\n",
    "    for string in text:\n",
    "        string = [word for word in string  if word in w2vmodel.wv.vocab and str(word) in idf_dict]\n",
    "        if string:\n",
    "            idfs = calc_idf(string)\n",
    "            w2vs = w2vmodel.wv[string]\n",
    "            strx = []\n",
    "            for ii in range(len(string)):\n",
    "                strx.append(w2vs[ii] * idfs[ii])\n",
    "                          \n",
    "            res.append(np.mean(strx, axis=0))\n",
    "        else:\n",
    "            res.append(np.zeros(e))\n",
    "    \n",
    "        #if i % 10000 == 0:\n",
    "        #    print(i)\n",
    "        #i+=1\n",
    "\n",
    "    return np.array(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k8kU3Db0Qivm",
    "outputId": "3a67ddc8-e5a7-40df-8b08-f009967a94ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding:  100\n",
      "mean w2v MAE: 1.0117697620964856\n",
      "IDF w2v MAE: 1.0099438899219475\n",
      "Embedding:  200\n",
      "mean w2v MAE: 0.9928280232720971\n",
      "IDF w2v MAE: 0.991608396073197\n",
      "Embedding:  300\n",
      "mean w2v MAE: 0.9839783812040752\n",
      "IDF w2v MAE: 0.980652526683772\n",
      "Embedding:  400\n",
      "mean w2v MAE: 0.9802495335563386\n",
      "IDF w2v MAE: 0.9779603412820319\n",
      "Embedding:  500\n",
      "mean w2v MAE: 0.9761492705804202\n",
      "IDF w2v MAE: 0.9748739077829126\n",
      "Embedding:  600\n",
      "mean w2v MAE: 0.973727697927954\n",
      "IDF w2v MAE: 0.9719845684899494\n",
      "Embedding:  700\n",
      "mean w2v MAE: 0.972539121813073\n",
      "IDF w2v MAE: 0.9719684582473583\n",
      "Embedding:  800\n",
      "mean w2v MAE: 0.9694097229834927\n",
      "IDF w2v MAE: 0.9684561917234308\n",
      "Embedding:  900\n",
      "mean w2v MAE: 0.9678558577705466\n",
      "IDF w2v MAE: 0.9671074201380211\n",
      "Embedding:  1000\n",
      "mean w2v MAE: 0.965329872882617\n",
      "IDF w2v MAE: 0.9648317458431299\n",
      "Embedding:  1100\n",
      "mean w2v MAE: 0.9643625987311143\n",
      "IDF w2v MAE: 0.9638742746952393\n",
      "Embedding:  1200\n",
      "mean w2v MAE: 0.9624001737133279\n",
      "IDF w2v MAE: 0.9617261094765887\n",
      "Embedding:  1300\n",
      "mean w2v MAE: 0.9618490703696136\n",
      "IDF w2v MAE: 0.960841307673016\n",
      "Embedding:  1400\n",
      "mean w2v MAE: 0.9619694456327407\n",
      "IDF w2v MAE: 0.9615641860689114\n",
      "Embedding:  1500\n",
      "mean w2v MAE: 0.9611661596847833\n",
      "IDF w2v MAE: 0.9608200468979734\n"
     ]
    }
   ],
   "source": [
    "history_m = []\n",
    "history_im = []\n",
    "\n",
    "for i in range(100, 1600, 100):\n",
    "    print('Embedding: ', i)\n",
    "\n",
    "    model_i = Word2Vec(list(df_train['tokens']), size=i, min_count = 50)\n",
    "\n",
    "    train_x_m = textembedding1(model_i, df_train['tokens'], i)\n",
    "    test_x_m = textembedding1(model_i, df_test['tokens'], i)\n",
    "    lm.fit(train_x_m, train_y)\n",
    "    y_pred_m = lm.predict(test_x_m)\n",
    "    m1 = MAE_score(test_y, y_pred_m)\n",
    "    print('mean w2v MAE:', m1)\n",
    "    history_m.append(m1)\n",
    "\n",
    "    train_x_mi = textembedding2(model_i, df_train['tokens'], i)\n",
    "    test_x_mi = textembedding2(model_i, df_test['tokens'], i)\n",
    "    lm.fit(train_x_mi, train_y)\n",
    "    y_pred_mi = lm.predict(test_x_mi)\n",
    "    m2 = MAE_score(test_y, y_pred_mi)\n",
    "    print('IDF w2v MAE:', m2)\n",
    "    history_im.append(m2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "pebtVyedQipc",
    "outputId": "7e66fa3d-d44d-4a35-fafc-3d06c463a47f"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "ticks = list(range(100, 1600, 100))\n",
    "plt.plot(ticks, history_m, label = \"Mean w2v\")\n",
    "plt.plot(ticks, history_im, label = \"IDF w2v\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Embedding size\")\n",
    "plt.ylabel(\"MAE score\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wxn2Pz_QZEs0"
   },
   "source": [
    "Можно увидеть что с увеличением эмбеддинга качество растет, но медленно. При этом IDF в среднем показывает чуть лучшие результаты"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lfWoDI_SUcER"
   },
   "source": [
    "Теперь попробуйте обучить логистическую регрессию на любых других эмбеддингах размерности 300 и сравните качество с Word2Vec.\n",
    "#### Выводы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "G2sOYLFOQhs3"
   },
   "outputs": [],
   "source": [
    "from gensim.models import FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "q1fUr4SFQhnp"
   },
   "outputs": [],
   "source": [
    "modelft = FastText(list(df_train['tokens']), size=300, min_count=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_RgRZ_gVezEQ",
    "outputId": "1af88d5c-eabc-4436-cdbc-016255eb4cc5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9911032724303668"
      ]
     },
     "execution_count": 34,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x_f = textembedding1(modelft, df_train['tokens'], 300)\n",
    "test_x_f = textembedding1(modelft, df_test['tokens'], 300)\n",
    "lm.fit(train_x_f, train_y)\n",
    "y_pred_f = lm.predict(test_x_f)\n",
    "MAE_score(test_y, y_pred_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bv8RWthJjVB1"
   },
   "source": [
    "Если сравнить это с показателями модели на усредненных word2vec, то качество практически не отличается\n",
    "\n",
    "Embedding:  300\n",
    "\n",
    "mean w2v MAE: 0.9838634660169936  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a1uY_7baUcER"
   },
   "source": [
    "### Часть 3. 6 баллов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2xcHo2fIUcES"
   },
   "source": [
    "Теперь давайте воспользуемся более продвинутыми методами обработки текстовых данных, которые мы проходили в нашем курсе. Обучите RNN/Transformer для предсказания пользовательской оценки. Получите ошибку меньше, чем во всех вышеперечисленных методах."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7t-FqnI1UcES"
   },
   "source": [
    "Если будете обучать RNN, попробуйте ограничить максимальную длину предложения. Некоторые отзывы могут быть слишком длинные относительно остальных.\n",
    "\n",
    "Чтобы пользоваться DataLoader, все его элементы должны быть одинаковой размерности. Для этого вы можете добавить нулевой паддинг ко всем предложениям (см пример pad_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Ens9bcEJUcES"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from collections import Counter\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "HOmxvndrUcET"
   },
   "outputs": [],
   "source": [
    "#WORDS = set()\n",
    "#for sent in list(df['positive']):\n",
    "#    for w in sent:\n",
    "#        WORDS.add(w)\n",
    "\n",
    "#for sent in list(df['negative']):\n",
    "#    for w in sent:\n",
    "#        WORDS.add(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jEO9xRmcEDbJ",
    "outputId": "70f7c152-4bda-4aed-8c1d-be87e93592b0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.88795"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tokens'].apply(len).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "2FmAC0ygSWD6"
   },
   "outputs": [],
   "source": [
    "df = df[df['tokens'].apply(len) < 15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "xB6gLseJLJfX"
   },
   "outputs": [],
   "source": [
    "df = df[df['tokens'].apply(len) > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "059jG__CNPL4",
    "outputId": "16f2310d-efc4-4112-d839-3d3be89c6edb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99991      [nothing, comfortable, rooms, wonderful, place]\n",
       "99992    [negative, lication, quite, good, facilities, ...\n",
       "99993    [room, tiny, bed, small, two, ac, noisy, locat...\n",
       "99997    [terrible, worn, mattress, dust, behind, headb...\n",
       "99999    [negative, great, breakfast, rooms, clean, loc...\n",
       "Name: tokens, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tokens'][-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yRPjgkSVMblI",
    "outputId": "e8521974-b9b6-4437-df84-e663789b6ac5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.828974288084048"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tokens'].apply(len).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "QxTdaZ-8Qmfz"
   },
   "outputs": [],
   "source": [
    "WORDS = set()\n",
    "\n",
    "for sent in df['tokens']:\n",
    "  for w in sent:\n",
    "    WORDS.add(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "SsxsLrF2UcEa"
   },
   "outputs": [],
   "source": [
    "int2word = dict(enumerate(tuple(WORDS)))\n",
    "word2int = {w: ii for ii, w in int2word.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "E4PblXajUcEc"
   },
   "outputs": [],
   "source": [
    "#MAX_LEN = max(max(df['positive'].apply(len)), max(df['negative'].apply(len)))\n",
    "MAX_LEN = max(df['tokens'].apply(len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0UaBtz9cQzli",
    "outputId": "43983402-4750-439d-99df-4c64bdaae9d8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_LEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "vInnp7jWUcEe"
   },
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "df['pos_pad'] = pad_sequence([torch.as_tensor([word2int[w] for w in seq][:MAX_LEN]) for seq in df['tokens']], \n",
    "                           batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "qGvY1HWgESr4"
   },
   "outputs": [],
   "source": [
    "reviews_ints = []\n",
    "for review in df['tokens']:\n",
    "    reviews_ints.append([word2int[word] for word in review])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "bx5-HGFPJlpC"
   },
   "outputs": [],
   "source": [
    "def pad_features(reviews_ints, seq_length):\n",
    "    ''' Return features of review_ints, where each review is padded with 0's \n",
    "        or truncated to the input seq_length.\n",
    "    '''\n",
    "    \n",
    "    # getting the correct rows x cols shape\n",
    "    features = np.zeros((len(reviews_ints), seq_length), dtype=int)\n",
    "\n",
    "    # for each review, I grab that review and \n",
    "    for i, row in enumerate(reviews_ints):\n",
    "        features[i, -len(row):] = np.array(row)[:seq_length]\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "6v7LHIIAJDg8"
   },
   "outputs": [],
   "source": [
    "pos_pad = pad_features(reviews_ints, seq_length=MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qEpQ1fyoETyQ",
    "outputId": "ab5f60cb-c785-4b89-effd-d37a0d7604c3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_pad[:2,:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "8R5e7vSKEVJW"
   },
   "outputs": [],
   "source": [
    "y = np.array(df['score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dOmM52SqEVGS",
    "outputId": "5267393e-dfbc-41b9-ebf6-1c5434ed826c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7.1,  7.5, 10. , ...,  5.4,  5. , 10. ])"
      ]
     },
     "execution_count": 25,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "rbQ5Rqk_EVDO"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(pos_pad, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s23JNSiuKun6"
   },
   "source": [
    "Все это было нужно чтобы не писать самому датасет, да"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "SDY_qtBgKuWq"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "\n",
    "train_data = TensorDataset(torch.from_numpy(X_train), torch.from_numpy(y_train))\n",
    "test_data = TensorDataset(torch.from_numpy(X_test), torch.from_numpy(y_test))\n",
    "\n",
    "\n",
    "batch_size = 1000\n",
    "\n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_data, shuffle=True, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "DNGq9AZvLj57"
   },
   "outputs": [],
   "source": [
    "train_on_gpu=torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "r88zjNIyLj1i"
   },
   "outputs": [],
   "source": [
    "class SentimentRNN(nn.Module):\n",
    "    \"\"\"\n",
    "    The RNN model that will be used to perform Sentiment analysis.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, vocab_size, output_size, embedding_dim, hidden_dim, n_layers, drop_prob=0.5):\n",
    "        \"\"\"\n",
    "        Initialize the model by setting up the layers.\n",
    "        \"\"\"\n",
    "        super(SentimentRNN, self).__init__()\n",
    "\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        # embedding and LSTM layers\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, n_layers, \n",
    "                            dropout=drop_prob, batch_first=True)\n",
    "        \n",
    "        # dropout layer\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        \n",
    "        # linear and sigmoid layers\n",
    "        self.fc = nn.Linear(hidden_dim, output_size)\n",
    "        \n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        \"\"\"\n",
    "        Perform a forward pass of our model on some input and hidden state.\n",
    "        \"\"\"\n",
    "        batch_size = x.size(0)\n",
    "\n",
    "        # embeddings and lstm_out\n",
    "        embeds = self.embedding(x)\n",
    "        lstm_out, hidden = self.lstm(embeds, hidden)\n",
    "    \n",
    "        # stack up lstm outputs\n",
    "        lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim)\n",
    "        \n",
    "        # dropout and fully-connected layer\n",
    "        out = self.dropout(lstm_out)\n",
    "        out = self.fc(out)\n",
    "        # sigmoid function\n",
    "        #sig_out = self.sig(out)\n",
    "        \n",
    "        # reshape to be batch_size first\n",
    "        #sig_out = sig_out.view(batch_size, -1)\n",
    "        #sig_out = sig_out[:, -1] # get last batch of labels\n",
    "        \n",
    "        # return last sigmoid output and hidden state\n",
    "        #return sig_out, hidden\n",
    "\n",
    "        out = out.view(batch_size, -1)\n",
    "        out= out[:,-1]\n",
    "        return out, hidden\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        ''' Initializes hidden state '''\n",
    "        # Create two new tensors with sizes n_layers x batch_size x hidden_dim,\n",
    "        # initialized to zero, for hidden state and cell state of LSTM\n",
    "        weight = next(self.parameters()).data\n",
    "        \n",
    "        if (train_on_gpu):\n",
    "            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda(),\n",
    "                  weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda())\n",
    "        else:\n",
    "            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_(),\n",
    "                      weight.new(self.n_layers, batch_size, self.hidden_dim).zero_())\n",
    "        \n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vZm_CfmrKuPp",
    "outputId": "4c6398cd-6e35-4ebd-eb47-4c99cff8dc33"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SentimentRNN(\n",
      "  (embedding): Embedding(14120, 200)\n",
      "  (lstm): LSTM(200, 200, num_layers=2, batch_first=True, dropout=0.5)\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      "  (fc): Linear(in_features=200, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(word2int)\n",
    "output_size = 1\n",
    "embedding_dim = 200\n",
    "hidden_dim = 200\n",
    "n_layers = 2\n",
    "\n",
    "net = SentimentRNN(vocab_size, output_size, embedding_dim, hidden_dim, n_layers)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "RvBbuD-2Mxe5"
   },
   "outputs": [],
   "source": [
    "lr=0.001\n",
    "\n",
    "criterion = nn.L1Loss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PXG6o-xKNMv9",
    "outputId": "54eb212c-efc2-4f73-c172-8656fbf61f0f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "epochs = 4 \n",
    "clip=5 \n",
    "\n",
    "if(train_on_gpu):\n",
    "    net.cuda()\n",
    "\n",
    "net.train()\n",
    "for e in range(epochs):\n",
    "    h = net.init_hidden(batch_size)\n",
    "   \n",
    "    for inputs, labels in train_loader:\n",
    "        \n",
    "        if(train_on_gpu):\n",
    "            inputs, labels = inputs.cuda(), labels.cuda()\n",
    "\n",
    "        h = tuple([each.data for each in h])\n",
    "\n",
    "        net.zero_grad()\n",
    "\n",
    "        output, h = net(inputs, h)\n",
    "\n",
    "\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(net.parameters(), clip)\n",
    "        optimizer.step()\n",
    "\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "HGHYkY9xSBfp"
   },
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "\n",
    "h = net.init_hidden(batch_size)\n",
    "\n",
    "net.eval()\n",
    "for inputs, labels in test_loader:\n",
    "\n",
    "    h = tuple([each.data for each in h])\n",
    "\n",
    "    if(train_on_gpu):\n",
    "        inputs, labels = inputs.cuda(), labels.cuda()\n",
    "    \n",
    "    output, h = net(inputs, h)\n",
    "    y_pred.append(output.squeeze().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qxAjOx6nU8nI",
    "outputId": "f6687ef2-c94b-4cf4-bf67-3af2cd528a37"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 55,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "oFGwMwHvVpVE"
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "preds = list(itertools.chain(*y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "io3PkwTMVuim"
   },
   "outputs": [],
   "source": [
    "preds = np.array(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nfRNMEa0UjqT",
    "outputId": "75c4b1b3-c353-4c29-dcad-3f409ce7c2e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9997635786589748\n"
     ]
    }
   ],
   "source": [
    "MAE_score(y_test, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dxCe-WTBLkik"
   },
   "source": [
    "Качество получилось так себе конечно, но используемая RNN модель изначально должна была предсказывать бинарную зависимую переменную и скорее всего я где-то накосячил когда переделывал ее для данной задачи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JItjdYvdKuLE"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WSG6xlljJbYT"
   },
   "outputs": [],
   "source": [
    "def pos_pad(sequence):\n",
    "    return pad_sequence([torch.as_tensor([word2int[w] for w in seq][:MAX_LEN]) for seq in sequence], \n",
    "                           batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "id": "o5EeKiM8UcEf"
   },
   "outputs": [],
   "source": [
    "class ReviewsDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df):\n",
    "        ## TODO\n",
    "        self.x = df['pos_pad']\n",
    "        self.y = df['score']\n",
    "        \n",
    "    def __len__(self):\n",
    "        ## TODO\n",
    "        return len(self.y)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        ## TODO\n",
    "        string = self.x[idx]\n",
    "        label = self.y[idx]\n",
    "\n",
    "        return string, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "id": "Vh5-U8aVUcEf"
   },
   "outputs": [],
   "source": [
    "batch_size = 1000\n",
    "\n",
    "train_dataset = ReviewsDataset(df_train)\n",
    "test_dataset = ReviewsDataset(df_test)\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(df_train, batch_size=batch_size)\n",
    "test_dataloader = torch.utils.data.DataLoader(df_test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7GCgILzrllS1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RV3NXUIslEl1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kl0SGgSjUcEj"
   },
   "source": [
    "### Бонус. 10 баллов\n",
    "\n",
    "Побейте качество 0.75 в [соревновании](https://www.kaggle.com/c/hseds-texts-2020/leaderboard). Можете воспользоваться вышеперечисленными методами или попробовать что-нибудь еще."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1LkIgtOKUcEk"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "hw3_Novikov.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
